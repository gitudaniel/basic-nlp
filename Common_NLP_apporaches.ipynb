{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Common NLP apporaches.ipynb",
      "provenance": [],
      "mount_file_id": "1IHCOll3HQkImbNneByrdHRGDQyVPHpy-",
      "authorship_tag": "ABX9TyPw/iQD6rpLdGQYGh+R2CgG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitudaniel/basic-nlp/blob/main/Common_NLP_apporaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAb5i94bI3fE",
        "outputId": "c339b959-3c77-499f-d945-33ba7108d584"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 523 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.21.6)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.6.0-py3-none-any.whl size=56459 sha256=cf5b1e0734f876392ceb5e43958c248b8329afc48ef530be285cc4c78b5ca39e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/83/71/a781667865955ae7dc18e5a4038401deb56d96eb85d3a5f1c0\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hbfdB_uGGaLO"
      },
      "outputs": [],
      "source": [
        "import np_utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing import sequence, text\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4s7RLHzIBxC",
        "outputId": "3cd96fec-62c3-4c3c-c5f4-dce029a0c2ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/NLP/Spooky Author Identification/test.zip' -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLsn3BnUJOCf",
        "outputId": "4ae9573d-6471-4bfb-90fb-1cd7699156fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/NLP/Spooky Author Identification/test.zip\n",
            "  inflating: /content/test.csv       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/NLP/Spooky Author Identification/train.zip' -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfarL3sPJ20u",
        "outputId": "d8de67b3-ecf3-49e8-b5c8-4d4677c8037b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/NLP/Spooky Author Identification/train.zip\n",
            "  inflating: /content/train.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/NLP/Spooky Author Identification/sample_submission.zip' -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSTbltNlJ4Xv",
        "outputId": "5ef58ae9-a797-4f7f-d7cd-ead19076a22e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/NLP/Spooky Author Identification/sample_submission.zip\n",
            "  inflating: /content/sample_submission.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "Qjk0r3_QJ69X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EjmIe_LxKDlb",
        "outputId": "2f18086d-bc56-4d79-9a3f-6c9e64cfb598"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2670c09-b700-4ecd-90a0-7e4c0559c904\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2670c09-b700-4ecd-90a0-7e4c0559c904')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2670c09-b700-4ecd-90a0-7e4c0559c904 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2670c09-b700-4ecd-90a0-7e4c0559c904');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_vBa6Tf9KFua",
        "outputId": "9934fd0a-1492-42f4-b2f9-71507de4d9a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text\n",
              "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
              "1  id24541  If a fire wanted fanning, it could readily be ...\n",
              "2  id00134  And when they had broken down the frail door t...\n",
              "3  id27757  While I was thinking how I should possibly man...\n",
              "4  id04081  I am not sure to what limit his knowledge may ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99c68349-1fa0-4a02-974e-86e5031ef445\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>And when they had broken down the frail door t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>While I was thinking how I should possibly man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>I am not sure to what limit his knowledge may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99c68349-1fa0-4a02-974e-86e5031ef445')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99c68349-1fa0-4a02-974e-86e5031ef445 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99c68349-1fa0-4a02-974e-86e5031ef445');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ys5nJ6iAKIOT",
        "outputId": "c3cc22f6-a8a7-484f-aa75-57e9fa0a8240"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id       EAP       HPL       MWS\n",
              "0  id02310  0.403494  0.287808  0.308698\n",
              "1  id24541  0.403494  0.287808  0.308698\n",
              "2  id00134  0.403494  0.287808  0.308698\n",
              "3  id27757  0.403494  0.287808  0.308698\n",
              "4  id04081  0.403494  0.287808  0.308698"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa086096-c67f-4d24-8b2f-124d4065de0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa086096-c67f-4d24-8b2f-124d4065de0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa086096-c67f-4d24-8b2f-124d4065de0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa086096-c67f-4d24-8b2f-124d4065de0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric\n",
        "    :param actual: Array containing actual target classes\n",
        "    :param predicted: Matrix with one prediction, one probability per class\n",
        "    \"\"\"\n",
        "    # convert actual to binary array if not already\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "metadata": {
        "id": "sONfPulhKKaL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(train.author.values)"
      ],
      "metadata": {
        "id": "3ETxmrOJLR4J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y,\n",
        "                                                  stratify=y,\n",
        "                                                  random_state=42,\n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "TunH2REJLdat"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.shape)\n",
        "print(xvalid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX_JuVt1Lpzv",
        "outputId": "fbf47696-1fbf-4cb0-b387-90d9e343a083"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17621,)\n",
            "(1958,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode',\n",
        "                      analyzer='word', token_pattern=r'\\w{1,}',\n",
        "                      ngram_range=(1, 3), use_idf=1, smooth_idf=1,\n",
        "                      sublinear_tf=1, stop_words='english')\n",
        "\n",
        "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
        "tfv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_tfv = tfv.transform(xtrain)\n",
        "xvalid_tfv = tfv.transform(xvalid)"
      ],
      "metadata": {
        "id": "m4F_O54gLszZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Logistic Regression on TF-IDF\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafkclO9SBNv",
        "outputId": "8b6c45b5-aae9-47fa-ba31-55c779227d70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.572 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_tfv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JKtYWpOSXDI",
        "outputId": "b131bb4a-bbf6-4e06-8e8b-076bace615bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17621x15102 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 198521 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctv = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n",
        "                      ngram_range=(1, 3), stop_words='english')\n",
        "\n",
        "# Fitting count vectorizer\n",
        "ctv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_ctv = ctv.transform(xtrain)\n",
        "xvalid_ctv = ctv.transform(xvalid)\n",
        "\n",
        "# Fitting simple logistic regression on counts\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_ctv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_ctv)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsOMJVYbSZdB",
        "outputId": "5cc1bd3e-fbae-48c9-b8c5-902c68444cb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.527 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Naive Bayes on TFIDF\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ55Gk09TQaK",
        "outputId": "9fe21ec8-11bf-4d7c-f264-67889caee1c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.578 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Naive Bayes on counts\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_ctv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_ctv)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa16eXH0T1U1",
        "outputId": "8a6e6d14-966d-4797-edc1-4464bd9dbaad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.485 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SVD on 120 components\n",
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xvalid_svd = svd.transform(xvalid_tfv)\n",
        "\n",
        "# Scale the data obtained from SVD\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)"
      ],
      "metadata": {
        "id": "0lidw0tAUM_T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple SVM\n",
        "clf = SVC(C=1.0, probability=True) # we need probabilities\n",
        "clf.fit(xtrain_svd_scl, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd_scl)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5u8EjUFU3ki",
        "outputId": "0f9c8b6f-8f3d-45b5-e12b-68979b0651be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.734 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting simple xgboost on tf-idf\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
        "                        subsample=0.8, nthreads=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NRtqI_ZWjcH",
        "outputId": "04e97d3f-d1a5-489f-ef67-5ae1ff747397"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.782 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple xgboost on tf-idf svd features\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
        "                        subsample=0.8, nthreads=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_svd, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh6AAiKwWYsg",
        "outputId": "99b0cee0-e4aa-41b0-9830-fb08bc1b08d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.763 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grid search"
      ],
      "metadata": {
        "id": "NmfE_XzGXqlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Hyperparameter tuning\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ],
      "metadata": {
        "id": "wjyHeS2AL5sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
      ],
      "metadata": {
        "id": "JEIZUaaaW-59"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD()\n",
        "\n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "clf = pipeline.Pipeline([('svd', svd),\n",
        "                          ('scl', scl),\n",
        "                          ('lr', lr_model)])"
      ],
      "metadata": {
        "id": "y5YuD_1HX1p_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'svd__n_components': [120, 180],\n",
        "              'lr__C': [0.1, 1.0, 10],\n",
        "              'lr__penalty': ['l1', 'l2'],\n",
        "              'lr__solver': ['liblinear']}"
      ],
      "metadata": {
        "id": "jificX7OYXhX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Grid Search model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                     verbose=10, n_jobs=-1, refit=True, cv=2)\n",
        "\n",
        "model.fit(xtrain_tfv, ytrain)\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameter set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9vvX0HoYr8l",
        "outputId": "24bb7b03-77db-449c-b46b-dc6e4ffb7df3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
            "Best score: -0.741\n",
            "Best parameter set:\n",
            "\tlr__C: 10\n",
            "\tlr__penalty: 'l1'\n",
            "\tlr__solver: 'liblinear'\n",
            "\tsvd__n_components: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = MultinomialNB()\n",
        "\n",
        "# create pipeline\n",
        "clf = pipeline.Pipeline([('nb', nb_model)])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize grid search model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                     verbose=10, n_jobs=-1, refit=True, cv=2)\n",
        "\n",
        "# Fit grid search model\n",
        "model.fit(xtrain_tfv, ytrain)\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XgzjL4Qa77S",
        "outputId": "67ee15f2-4d0a-4528-f214-2046e1e3059e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "Best score: -0.492\n",
            "Best parameters set:\n",
            "\tnb__alpha: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls 'drive/MyDrive/NLP/GloVe vectors/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbp-syVYpahp",
        "outputId": "b574b82e-b35e-4a3c-db93-38de3b3f4998"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.840B.300d.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/NLP/GloVe vectors/glove.840B.300d.zip' -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1HTrhyTOg_u",
        "outputId": "dc49f79d-92bc-404a-f5ab-a9b15dfca6ac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/NLP/GloVe vectors/glove.840B.300d.zip\n",
            "  inflating: /content/glove.840B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.840B.300d.txt', 'r', encoding='utf8', errors='ignore')\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    if len(values) == 301:\n",
        "        pass\n",
        "    else:\n",
        "        idx = len(values) - 301\n",
        "        values = values[idx:]\n",
        "    word = values[0]\n",
        "    # try:\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    # except ValueError:\n",
        "        # import pdb; pdb.set_trace()\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7BqKjnspgdr",
        "outputId": "66de8f4e-18ad-4eaa-804d-c6680227e08e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2196017it [03:43, 9835.77it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2195885 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sent2vec(s):\n",
        "    \"\"\"Creates a normalized vector for the whole sentence.\"\"\"\n",
        "    words = str(s).lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    words = [w for w in words if w.isalpha()]\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(embeddings_index[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    if type(v) != np.ndarray:\n",
        "        return np.zeros(300)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ],
      "metadata": {
        "id": "3UdV9hjqvnws"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentence vectors using the above function for training and validation sets\n",
        "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
        "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Cu0uDN20E4",
        "outputId": "3c7dfc87-ddf5-4915-cdf0-78e821ca6931"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17621/17621 [00:07<00:00, 2351.55it/s]\n",
            "100%|██████████| 1958/1958 [00:00<00:00, 2425.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_glove = np.array(xtrain_glove)\n",
        "xvalid_glove = np.array(xvalid_glove)"
      ],
      "metadata": {
        "id": "VSjOCULj3GHc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq8k583S3xaw",
        "outputId": "85cbe2d0-a19d-4864-b3f6-2d04bbb2090e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xvalid_glove.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJ7JtHr3z7q",
        "outputId": "38bb5e33-0791-4dbd-eafb-76a9469c25da"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1958, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier(nthread=10, silent=False)\n",
        "clf.fit(xtrain_glove, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_glove)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDqWP9vQ31xm",
        "outputId": "2fabe5a6-679b-4df8-c3ae-7c4c972af215"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.796 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n",
        "clf.fit(xtrain_glove, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_glove)\n",
        "\n",
        "print(\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhMPyrUP4I4W",
        "outputId": "b6b9fd70-e49a-4982-f767-6d78347a51a0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.690 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep learning"
      ],
      "metadata": {
        "id": "o7R-b53c6bpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scl = preprocessing.StandardScaler()\n",
        "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
        "xvalid_glove_scl = scl.fit_transform(xvalid_glove)"
      ],
      "metadata": {
        "id": "d-LUWn3Z4-pY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "o8NvlopQPsPW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels\n",
        "ytrain_enc = np_utils.to_categorical(ytrain)\n",
        "yvalid_enc = np_utils.to_categorical(yvalid)"
      ],
      "metadata": {
        "id": "fnM1EB1uOVJz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple 3 layer neural net\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(300, input_dim=300, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "Gva1IvkZOkgL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64,\n",
        "          epochs=5, verbose=1,\n",
        "          validation_data=(xvalid_glove_scl, yvalid_enc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBvY1-GmQO8B",
        "outputId": "718210a5-5838-4d00-dcb6-1ef9cd7a28c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "276/276 [==============================] - 4s 10ms/step - loss: 0.9071 - val_loss: 0.7148\n",
            "Epoch 2/5\n",
            "276/276 [==============================] - 3s 11ms/step - loss: 0.6977 - val_loss: 0.6765\n",
            "Epoch 3/5\n",
            "276/276 [==============================] - 4s 13ms/step - loss: 0.6415 - val_loss: 0.6627\n",
            "Epoch 4/5\n",
            "276/276 [==============================] - 4s 14ms/step - loss: 0.5981 - val_loss: 0.6555\n",
            "Epoch 5/5\n",
            "276/276 [==============================] - 2s 9ms/step - loss: 0.5586 - val_loss: 0.6613\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe035797d90>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text data\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 70\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "\n",
        "# zero pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "metadata": {
        "id": "0-qFNzT7QhXN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an embedding matrix for words in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSdv_q_eRpVA",
        "outputId": "b5251c37-e6bd-45cc-ac24-684f835c2b3e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25943/25943 [00:00<00:00, 219257.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                    300,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_len,\n",
        "                    trainable=False))\n",
        "\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "tENcwfrZSLPS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1,\n",
        "          validation_data=(xvalid_pad, yvalid_enc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXyzkRexTGOi",
        "outputId": "7615c8f4-d655-416f-f564-92e98757017e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 107s 3s/step - loss: 1.0487 - val_loss: 0.9114\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 65s 2s/step - loss: 0.8964 - val_loss: 0.7581\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.8188 - val_loss: 0.7230\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.7899 - val_loss: 0.6887\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.7652 - val_loss: 0.6760\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.7380 - val_loss: 0.6626\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.7275 - val_loss: 0.6385\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.7139 - val_loss: 0.6465\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.6869 - val_loss: 0.6134\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.6603 - val_loss: 0.6072\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.6420 - val_loss: 0.5836\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.6227 - val_loss: 0.5671\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.6034 - val_loss: 0.5475\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5851 - val_loss: 0.5780\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5801 - val_loss: 0.5416\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.5569 - val_loss: 0.5334\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.5561 - val_loss: 0.5313\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5361 - val_loss: 0.5215\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5277 - val_loss: 0.5244\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5190 - val_loss: 0.5717\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4942 - val_loss: 0.5146\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4907 - val_loss: 0.5014\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4868 - val_loss: 0.5271\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4721 - val_loss: 0.5137\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4581 - val_loss: 0.5748\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.4585 - val_loss: 0.5139\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4375 - val_loss: 0.5079\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4442 - val_loss: 0.5043\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4234 - val_loss: 0.5268\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4171 - val_loss: 0.5178\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4211 - val_loss: 0.5188\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.4069 - val_loss: 0.5134\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3987 - val_loss: 0.5101\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3922 - val_loss: 0.5212\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3919 - val_loss: 0.4941\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3876 - val_loss: 0.5029\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.3727 - val_loss: 0.5104\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3736 - val_loss: 0.5069\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3703 - val_loss: 0.5236\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3629 - val_loss: 0.4994\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3593 - val_loss: 0.5109\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3467 - val_loss: 0.5343\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3434 - val_loss: 0.4998\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3374 - val_loss: 0.5271\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3372 - val_loss: 0.5503\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.3404 - val_loss: 0.5376\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3229 - val_loss: 0.5476\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.3298 - val_loss: 0.5163\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.3240 - val_loss: 0.5198\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3230 - val_loss: 0.5166\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.3122 - val_loss: 0.5240\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.3080 - val_loss: 0.5248\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.3058 - val_loss: 0.5392\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.3071 - val_loss: 0.5222\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 65s 2s/step - loss: 0.2990 - val_loss: 0.5367\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.2891 - val_loss: 0.5385\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2990 - val_loss: 0.5221\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2910 - val_loss: 0.5216\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2889 - val_loss: 0.5165\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2782 - val_loss: 0.5320\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2822 - val_loss: 0.5321\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2802 - val_loss: 0.5578\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2788 - val_loss: 0.5401\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2729 - val_loss: 0.5353\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2687 - val_loss: 0.5377\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2676 - val_loss: 0.5527\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2629 - val_loss: 0.5487\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2567 - val_loss: 0.5440\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2556 - val_loss: 0.5459\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2520 - val_loss: 0.5572\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2532 - val_loss: 0.5521\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2530 - val_loss: 0.5884\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2520 - val_loss: 0.5715\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2431 - val_loss: 0.5567\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2529 - val_loss: 0.5347\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2386 - val_loss: 0.5667\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2380 - val_loss: 0.5725\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2373 - val_loss: 0.5720\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2431 - val_loss: 0.5640\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2331 - val_loss: 0.5668\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2368 - val_loss: 0.5670\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2348 - val_loss: 0.5632\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2284 - val_loss: 0.5680\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2279 - val_loss: 0.5874\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2302 - val_loss: 0.5648\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.2245 - val_loss: 0.5691\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2165 - val_loss: 0.5868\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2167 - val_loss: 0.5805\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2238 - val_loss: 0.5745\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.2211 - val_loss: 0.5768\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2141 - val_loss: 0.5994\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2123 - val_loss: 0.5855\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2180 - val_loss: 0.5910\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2076 - val_loss: 0.5996\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2125 - val_loss: 0.6014\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2076 - val_loss: 0.5941\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.2113 - val_loss: 0.6032\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 61s 2s/step - loss: 0.2059 - val_loss: 0.6302\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.2047 - val_loss: 0.6102\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.2037 - val_loss: 0.5878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe031b80810>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "          300,\n",
        "          weights=[embedding_matrix],\n",
        "          input_length=max_len,\n",
        "          trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3,\n",
        "                          verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100,\n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc),\n",
        "          callbacks=[earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gEGNkuE5TU8t",
        "outputId": "fa104df7-62ff-47d6-e413-04f4d46e15bf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 309s 9s/step - loss: 1.0515 - val_loss: 0.9339\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 289s 8s/step - loss: 0.9020 - val_loss: 0.7634\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 278s 8s/step - loss: 0.8339 - val_loss: 0.7308\n",
            "Epoch 4/100\n",
            " 7/35 [=====>........................] - ETA: 3:39 - loss: 0.7993"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7fa27cb965a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100,\n\u001b[1;32m     26\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myvalid_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m           callbacks=[earlystop])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembling"
      ],
      "metadata": {
        "id": "quT3BQxnNX0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
        "    datefmg=\"%H:%M:%S\", stream=sys.stdout)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class Ensembler(object):\n",
        "    def __init__(self, model_dict, num_folds=3, task_type='classification',\n",
        "                 optimize=roc_auc_score, lower_is_better=False,\n",
        "                 save_path=None):\n",
        "        \"\"\"\n",
        "        Ensembler init function\n",
        "        :param model_dict: model dictionary\n",
        "        :param num_folds: the number of folds for ensembling\n",
        "        :param task_type: classification or regression\n",
        "        :param optimize: the function to optimize for, e.g. AUC, logloss, etc.\n",
        "        Must have two arguments y_test and y_pred\n",
        "        :param lower_is_better: is a lower or higher value of optimization\n",
        "        function better\n",
        "        :param save_path: path to which model pickles will be dumped to along \n",
        "        with generated predictions or None\n",
        "        \"\"\"\n",
        "        self.model_dict = model_dict\n",
        "        self.levels = len(self.model_dict)\n",
        "        self.num_folds = num_folds\n",
        "        self.task_type = task_type\n",
        "        self.optimize = optimize\n",
        "        self.lower_is_better = lower_is_better\n",
        "        self.save_path = save_path\n",
        "\n",
        "        self.training_data = None\n",
        "        self.test_data = None\n",
        "        self.y = None\n",
        "        self.lbl_enc = None\n",
        "        self.y_enc = None\n",
        "        self.train_prediction_dict = None\n",
        "        self.test_prediction_dict = None\n",
        "        self.num_classes = None\n",
        "\n",
        "    def fit(self, training_data, y, lentrain):\n",
        "        \"\"\"\n",
        "        :param training_data: training data in tabular format\n",
        "        :param y: binary, multi_class or regression\n",
        "        :return: chain of models to be used in prediction\n",
        "        \"\"\"\n",
        "\n",
        "        self.training_data = training_data\n",
        "        self.y = y\n",
        "\n",
        "        if self.task_type == 'classification':\n",
        "            self.num_classes = len(np.unique(self.y))\n",
        "            logger.info(\"Found %d classes\", self.num_classes)\n",
        "            self.lbl_enc = LabelEncoder()\n",
        "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
        "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
        "            train_prediction_shape = (lentrain, self.num_classes)\n",
        "        else:\n",
        "            self.num_classes = -1\n",
        "            self.y_enc = self.y\n",
        "            kf = KFold(n_splits=self.num_folds)\n",
        "            train_prediction_shape = (lentrain, 1)\n",
        "\n",
        "        self.train_prediction_dict = {}\n",
        "        for level in range(self.levels):\n",
        "            self.train_prediction_dict[level] = np.zeros(\n",
        "                            (train_prediction_shape[0],\n",
        "                             train_prediction_shape[1] * len(self.model_dict[level])))\n",
        "            \n",
        "        for level in range(self.levels):\n",
        "            if level == 0:\n",
        "                temp_train = self.training_data\n",
        "            else:\n",
        "                temp_train = self.train_prediction_dict[level - 1]\n",
        "\n",
        "            for model_num, model in enumerate(self.model_dict[level]):\n",
        "                validation_scores = []\n",
        "                foldnum = 1\n",
        "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
        "                    logger.info(\"Training level %d Fold # %d. Model # %d\",\n",
        "                                level, foldnum, model_num)\n",
        "                    if level !=0:\n",
        "                        l_training_data = temp_train[train_index]\n",
        "                        l_validation_data = temp_train[valid_index]\n",
        "                        model.fit(l_training_data, self.y_enc[train_index])\n",
        "\n",
        "                    else:\n",
        "                        l0_training_data = temp_train[0][model_num]\n",
        "                        if type(l0_training_data) == list:\n",
        "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
        "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
        "\n",
        "                        else:\n",
        "                            l_training_data = l0_training_data[train_index]\n",
        "                            l_validation_data = l0_training_data[valid_index]\n",
        "\n",
        "                        model.fit(l_training_data, self.y_enc[train_index])\n",
        "\n",
        "                    logger.info(\"Predicting level %d. Fold # %d. Model # %d\",\n",
        "                                level, foldnum, model_num)\n",
        "                    \n",
        "                    if self.task_type == 'classification':\n",
        "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
        "                        self.train_prediction_dict[level][valid_index,\n",
        "                                (model_num * self.num_classes): (model_num * self.num_classes) + self.num_classes] = temp_train_predictions\n",
        "                    \n",
        "                    else:\n",
        "                        temp_train_predictions = model.predict(l_validation_data)\n",
        "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
        "\n",
        "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
        "                    validation_scores.append(validation_score)\n",
        "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation_score = %f\",\n",
        "                                level, foldnum, model_num, validation_score)\n",
        "                    foldnum += 1\n",
        "                \n",
        "                avg_score = np.mean(validation_scores)\n",
        "                std_score = np.std(validation_scores)\n",
        "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\",\n",
        "                            level, model_num, avg_score, std_score)\n",
        "                \n",
        "            logger.info(\"Saving predictions for level # %d.\", level)\n",
        "            train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
        "            train_predictions_df.to_csv(os.path.join(self.save_path, 'train_predictions_level_' + str(level) + \".csv\"),\n",
        "                                        index=False, header=None)\n",
        "            \n",
        "        return self.train_prediction_dict\n",
        "\n",
        "    def predict(self, test_data, lentest):\n",
        "        self.test_data = test_data\n",
        "        if self.task_type == 'classification':\n",
        "            test_prediction_shape = (lentest, self.num_classes)\n",
        "        else:\n",
        "            test_prediction_shape = (lentest, 1)\n",
        "\n",
        "        self.test_prediction_dict = {}\n",
        "        for level in range(self.levels):\n",
        "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
        "                                                test_prediction_shape[1] * len(self.model_dict[level])))\n",
        "        self.test_data = test_data\n",
        "        for level in range(self.levels):\n",
        "            if level == 0:\n",
        "                temp_train = self.training_data\n",
        "                temp_test = self.test_data\n",
        "            else:\n",
        "                temp_train = self.train_prediction_dict[level - 1]\n",
        "                temp_test = self.test_prediction_dict[level - 1]\n",
        "\n",
        "            for model_num, model in enumerate(self.model_dict[level]):\n",
        "                logger.info(\"Training Fulldata Level %d. Model # %d.\",\n",
        "                            level, model_num)\n",
        "                if level == 0:\n",
        "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
        "                else:\n",
        "                    model.fit(temp_train, self.y_enc)\n",
        "\n",
        "                logger.info(\"Predicting Test Level %d. Model # %d\",\n",
        "                            level, model_num)\n",
        "                \n",
        "                if self.task_type == \"classification\":\n",
        "                    if level == 0:\n",
        "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
        "                    else:\n",
        "                        temp_test_predictions = model.predict_proba(temp_test)\n",
        "\n",
        "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes)\n",
        "                        + self.num_classes] = temp_test_predictions\n",
        "                \n",
        "                else:\n",
        "                    if level == 0:\n",
        "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
        "                    else:\n",
        "                        temp_test_predictions = model.predict(temp_test)\n",
        "\n",
        "                    self.test_predictions_dict[level][:, model_num] = temp_test_predictions\n",
        "\n",
        "            test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
        "            test_predictions_df.to_csv(os.path.join(self.save_path,\n",
        "                                            \"test_predictions_level_\" + str(level) + \".csv\"),\n",
        "                                       index=False, header=None)\n",
        "        return self.test_prediction_dict"
      ],
      "metadata": {
        "id": "U_ejzfPovUjc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the data to be used for every level of ensembling\n",
        "train_data_dict = {0: [xtrain_tfv, xtrain_ctv, xtrain_tfv, xtrain_ctv],\n",
        "                   1: [xtrain_glove]}\n",
        "test_data_dict = {0: [xvalid_tfv, xvalid_ctv, xvalid_tfv, xvalid_ctv],\n",
        "                  1: [xvalid_glove]}\n",
        "\n",
        "model_dict = {0: [LogisticRegression(), LogisticRegression(), MultinomialNB(alpha=0.1), MultinomialNB()],\n",
        "              1: [xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7)]}\n",
        "\n",
        "ens = Ensembler(model_dict=model_dict, num_folds=3, task_type='classification',\n",
        "                optimize=multiclass_logloss, lower_is_better=True, save_path='')\n",
        "\n",
        "ens.fit(train_data_dict, ytrain, lentrain=xtrain_glove.shape[0])\n",
        "preds = ens.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDX86JOPs6D",
        "outputId": "cb123f38-e833-49e2-f691-24317d71d7cb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiclass_logloss(yvalid, preds[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIlqOiZdmuhy",
        "outputId": "bc48a95f-43fe-4db7-c322-f246426dda02"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4239630101725967"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FwgL_LZVm1-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}